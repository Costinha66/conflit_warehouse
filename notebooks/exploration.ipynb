{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff31113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>country_of_asylum</th>\n",
       "      <th>country_of_origin</th>\n",
       "      <th>refugees</th>\n",
       "      <th>returned_refugees</th>\n",
       "      <th>asylum_seekers</th>\n",
       "      <th>idps</th>\n",
       "      <th>returned_idps</th>\n",
       "      <th>stateless</th>\n",
       "      <th>hst</th>\n",
       "      <th>ooc</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>AFG</td>\n",
       "      <td>AFG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2886317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82595</td>\n",
       "      <td>2025-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>ALB</td>\n",
       "      <td>AFG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>EGY</td>\n",
       "      <td>AFG</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>ARG</td>\n",
       "      <td>AFG</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>ARM</td>\n",
       "      <td>AFG</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year country_of_asylum country_of_origin  refugees  returned_refugees  \\\n",
       "0  2020               AFG               AFG         0                  0   \n",
       "1  2020               ALB               AFG         0                  0   \n",
       "2  2020               EGY               AFG        34                  0   \n",
       "3  2020               ARG               AFG        12                  0   \n",
       "4  2020               ARM               AFG         5                  0   \n",
       "\n",
       "   asylum_seekers     idps  returned_idps  stateless  hst    ooc       date  \n",
       "0               0  2886317              0          0    0  82595 2025-09-04  \n",
       "1               0        0              0          0    0      5 2025-09-04  \n",
       "2              44        0              0          0    0      0 2025-09-04  \n",
       "3               0        0              0          0    0      0 2025-09-04  \n",
       "4               0        0              0          0    0      0 2025-09-04  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "out_path_parquet = \"/home/faacosta0245695/conflit/conflit_warehouse/data/bronze/unhcr/date=2025-09-04/part-000.parquet\"\n",
    "df = con.execute(\"\"\" Select * from read_parquet(?) \"\"\",[str(out_path_parquet)]).df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b0a69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc1b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faacosta0245695/conflit/conflit_warehouse/data/bronze/unhcr/date=2025-09-04 [] part-000.parquet\n"
     ]
    }
   ],
   "source": [
    "from dis import disco\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "path = Path(r\"/home/faacosta0245695/conflit/conflit_warehouse/data/bronze\")\n",
    "def discovery (path_warehouse: Path, chunk_size=8192):\n",
    "    for root, dirs, files in os.walk(path_warehouse):\n",
    "        for file in files:\n",
    "            if file.endswith('.parquet'):\n",
    "                print(root, file)\n",
    "discovery(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f88a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "474bc0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'file_path': '/home/faacosta0245695/conflit/conflit_warehouse/data/bronze/unhcr/date=2025-09-04/part-000.parquet', 'content_hash': '6ae7cf49a930577cc4a3f216f2e09539fe1b9e7eb7ac0731b820ebc8189acd8a', 'file_size': 31338, 'discovered_at': datetime.datetime(2025, 9, 8, 15, 54, 59, 285006), 'source_partition': 'date=2025-09-04'}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "def compute_file_hash(path: Path, chunk_size=65536) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        while chunk := f.read(chunk_size):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def discovery(path_warehouse: Path, chunk_size=65536):\n",
    "    records = []\n",
    "    for root, _, files in os.walk(path_warehouse):\n",
    "        for file in files:\n",
    "            if file.endswith(\".parquet\"):\n",
    "                file_path = Path(root) / file\n",
    "                records.append({\n",
    "                    \"file_path\": str(file_path),\n",
    "                    \"content_hash\": compute_file_hash(file_path, chunk_size),\n",
    "                    \"file_size\": file_path.stat().st_size,\n",
    "                    \"discovered_at\": datetime.now(),\n",
    "                    \"source_partition\": next((p for p in file_path.parts if p.startswith(\"date=\")), None)\n",
    "                })\n",
    "    return records\n",
    "\n",
    "# Example usage\n",
    "bronze_path = Path(\"/home/faacosta0245695/conflit/conflit_warehouse/data/bronze\")\n",
    "files = discovery(bronze_path)\n",
    "print(files[:2])  # peek first two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aaeb3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "def supports_merge(con: duckdb.DuckDBPyConnection) -> bool:\n",
    "    try:\n",
    "        con.execute(\"CREATE TEMP TABLE _a(x INT);\")\n",
    "        con.execute(\"CREATE TEMP TABLE _b(x INT);\")\n",
    "        con.execute(\"MERGE INTO _a a USING _b b ON a.x = b.x \"\n",
    "                    \"WHEN MATCHED THEN UPDATE SET x=b.x \"\n",
    "                    \"WHEN NOT MATCHED THEN INSERT VALUES (b.x);\")\n",
    "        return True\n",
    "    except duckdb.Error:\n",
    "        return False\n",
    "    finally:\n",
    "        con.execute(\"DROP TABLE IF EXISTS _a;\")\n",
    "        con.execute(\"DROP TABLE IF EXISTS _b;\")\n",
    "con = duckdb.connect()\n",
    "supports_merge(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd35e8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>partition_key</th>\n",
       "      <th>reason</th>\n",
       "      <th>first_seen_at</th>\n",
       "      <th>last_seen_at</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>refugee_displacement_conformed</td>\n",
       "      <td>2020</td>\n",
       "      <td>pending_manifest</td>\n",
       "      <td>2025-09-15 14:07:34.192</td>\n",
       "      <td>2025-09-15 14:07:34.192</td>\n",
       "      <td>dirty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           entity partition_key            reason  \\\n",
       "0  refugee_displacement_conformed          2020  pending_manifest   \n",
       "\n",
       "            first_seen_at            last_seen_at status  \n",
       "0 2025-09-15 14:07:34.192 2025-09-15 14:07:34.192  dirty  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb \n",
    "con = duckdb.connect(\"/home/faacosta0245695/conflit/conflit_warehouse/warehouse/database.db\")\n",
    "con.execute(\"\"\"Select * from dirty_partitions\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0d46e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'refugee_displacement_conformed', 'partition_key': '2020', 'inputs': [{'file_path': '/home/faacosta0245695/conflit/conflit_warehouse/data/bronze/unhcr/date=2025-09-09/2020-2020-part-000.parquet', 'content_hash': '6ae7cf49a930577cc4a3f216f2e09539fe1b9e7eb7ac0731b820ebc8189acd8a', 'file_size': 31338, 'discovered_at': Timestamp('2025-09-09 11:55:06.614298'), 'status': 'pending'}]}\n"
     ]
    }
   ],
   "source": [
    "import duckdb \n",
    "con = duckdb.connect(\"/home/faacosta0245695/conflit/conflit_warehouse/warehouse/database.db\")\n",
    "def planner(con):\n",
    "    dirty = con.execute(\"\"\" SELECT entity, partition_key\n",
    "                                FROM dirty_partitions\n",
    "                                WHERE status = 'dirty'\n",
    "                                ORDER BY last_seen_at, entity, partition_key; \"\"\").df()\n",
    "    for entity, partition_key in zip(dirty['entity'],dirty['partition_key']):\n",
    "        plan_df  = con.execute(f\"\"\" \n",
    "            WITH candidates AS (\n",
    "                SELECT mpl.file_path, mpl.content_hash, m.file_size, m.discovered_at, m.status\n",
    "                FROM manifest_partition_link mpl\n",
    "                JOIN ingest_manifest m\n",
    "                    ON m.file_path = mpl.file_path\n",
    "                AND m.content_hash = mpl.content_hash\n",
    "                WHERE mpl.entity = ?\n",
    "                    AND mpl.partition_key = ?\n",
    "                ),\n",
    "                latest_per_path AS (\n",
    "                SELECT * EXCLUDE rn\n",
    "                FROM (\n",
    "                    SELECT *, ROW_NUMBER() OVER (PARTITION BY file_path ORDER BY discovered_at DESC) rn\n",
    "                    FROM candidates\n",
    "                    WHERE status IN ('pending','processed')\n",
    "                ) WHERE rn = 1\n",
    "                )\n",
    "                SELECT * FROM latest_per_path\n",
    "                ORDER BY discovered_at ASC, file_path ASC;\n",
    "    \n",
    "            \"\"\",[entity, partition_key]).df()\n",
    "        if plan_df.empty:\n",
    "            pass\n",
    "\n",
    "        yield {\n",
    "            \"entity\": entity,\n",
    "            \"partition_key\": partition_key,\n",
    "            \"inputs\": plan_df.to_dict(\"records\"),\n",
    "        }        \n",
    "for i in planner(con):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7241f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      country_origin country_destination  refugees  asylum_seekers     idps  \\\n",
      "0                AFG                 AFG         0               0  2553390   \n",
      "1                AFG                 EGY        28              36        0   \n",
      "2                AFG                 ARG        12               0        0   \n",
      "3                AFG                 ARM         5               0        0   \n",
      "4                AFG                 AUS     11585            1710        0   \n",
      "...              ...                 ...       ...             ...      ...   \n",
      "34706            ZWE                 SWE        24               0        0   \n",
      "34707            ZWE                 CHE         9               5        0   \n",
      "34708            ZWE                 USA       676            3037        0   \n",
      "34709            ZWE                 ZMB        10              15        0   \n",
      "34710            ZWE                 ZWE         0               0        0   \n",
      "\n",
      "       stateless  hst     ooc  year _bronze_file _ingest_run_id  \\\n",
      "0              0    0  447093  2019         None           None   \n",
      "1              0    0       0  2019         None           None   \n",
      "2              0    0       0  2019         None           None   \n",
      "3              0    0       0  2019         None           None   \n",
      "4              0    0       0  2019         None           None   \n",
      "...          ...  ...     ...   ...          ...            ...   \n",
      "34706          0    0       0  2024         None           None   \n",
      "34707          0    0       0  2024         None           None   \n",
      "34708          0    0       0  2024         None           None   \n",
      "34709          0    0       0  2024         None           None   \n",
      "34710          0    0     126  2024         None           None   \n",
      "\n",
      "      _transform_version  \n",
      "0                   None  \n",
      "1                   None  \n",
      "2                   None  \n",
      "3                   None  \n",
      "4                   None  \n",
      "...                  ...  \n",
      "34706               None  \n",
      "34707               None  \n",
      "34708               None  \n",
      "34709               None  \n",
      "34710               None  \n",
      "\n",
      "[34711 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "def load_schema(path: Path):\n",
    "    with open(path, \"r\") as f:\n",
    "        schema = yaml.safe_load(f)\n",
    "    return schema\n",
    "def harmonize(df_raw: pd.DataFrame, schema: dict) -> pd.DataFrame:\n",
    "    rename_map = {}\n",
    "    casts = {}\n",
    "    for col in schema[\"columns\"]:\n",
    "        canonical = col[\"name\"]\n",
    "        found = next((c for c in col[\"source\"] if c in df_raw.columns), None)\n",
    "        if found:\n",
    "            rename_map[found] = canonical\n",
    "        casts[canonical] = col[\"type\"]\n",
    "    \n",
    "    df = df_raw.rename(columns=rename_map)\n",
    "    \n",
    "    for col in [c[\"name\"] for c in schema[\"columns\"]]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    \n",
    "    for col, typ in casts.items():\n",
    "        if typ == \"BIGINT\":\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"Int64\")\n",
    "        elif typ == \"DOUBLE\":\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        elif typ == \"STRING\":\n",
    "            df[col] = df[col].astype(\"string\")\n",
    "        elif typ == \"DATE\":\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "    \n",
    "    for col in schema.get(\"lineage_columns\", []):\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    \n",
    "    df = df[[c[\"name\"] for c in schema[\"columns\"]] + schema.get(\"lineage_columns\", [])]\n",
    "    return df\n",
    "raw = pd.read_csv(\"/home/faacosta0245695/conflit/conflit_warehouse/data/raw/unhcr/persons_of_concern.csv\")\n",
    "schema = load_schema(\"/home/faacosta0245695/conflit/conflit_warehouse/schemas/refugees_stack.yaml\")\n",
    "\n",
    "print(harmonize(raw,schema))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
